num_classes <- length(unique(y)) #amount of classes
I <- diag(num_classes) #Identity matrix
Y <- matrix(0, m, num_classes) #Binary matrix of the class
for(i in 1:m){
Y[i,] <- I[y[i],]
}
#Column_Names and constructing the dataset with binary label
labelColumnNames <- paste("label", 0:9, sep = "")
featuresColumnNames <- colnames(digits_dataset)[-1]
#Calculation for 60/20/20
b1 <- m * 0.6
b2 <- b1 + m * 0.2
#Separate dataset into 60/20/20
digits_train_set <- digits_dataset[1:b1, ]
digits_validation_set <- digits_dataset[(b1+1):b2, ]
digits_test_set <- digits_dataset[(b2+1):m, ]
#Binary dataset for Training the model
digits_train_binary <- cbind(Y[1:b1,], digits_train_set[,-1])
colnames(digits_train_binary) <- c(labelColumnNames, featuresColumnNames)
###Trainining model###
print("Training Neural Network...")
f <- as.formula(paste(paste(labelColumnNames, collapse = "+"),
"~",
paste(featuresColumnNames, collapse = "+")))
model <- neuralnet(f, data=digits_train_binary, hidden=hidden_layer_size,
threshold = 0.01, stepmax = maxiter, lifesign="full",
lifesign.step = 10, linear.output = FALSE)
###Training fit and test accuracy
print("Model evaluation...")
#Classify the data
classTrain <- classify(model, digits_train_set[,-1])
classTest <- classify(model, digits_test_set[,-1])
#Calculate error
trainFit <- round(mean(digits_train_set[1] == classTrain), digits=2)
testAcc <- round(mean(digits_test_set[1] == classTest), digits=2)
print(paste("Training fit:", trainFit*100, "%"))
print(paste("Test accuracy:", testAcc*100, "%"))
#main project script
#R Digits Recognition Neural Networks
#Daniel Freitas and Alex Shkunov
#
#Date: 23.10.2014
#Thesis: Haaga-Helia UAS
#Removes objects from main memory
rm(list=ls())
#Import stuff
library(neuralnet)
source('classify.r')
#Global variables
digits_FileName <- "../trainLoadTry_headers.csv"
hidden_layer_size <- 5
maxiter = 200 # Optimisation steps for Performance control
tr = 5 #Threshold for partial derevative for Performance control
#run actual stuff
print("Starting Actual Stuff")
###Data preprocessing###
#loading into the main memory
digits_dataset <- read.csv(digits_FileName)
print("Data Loaded...")
m <- nrow(digits_dataset)
#Label binary transformation
y <- digits_dataset[,1] + 1 # +1 for shift, so Zero is 1st class, One is 2nd class....
num_classes <- length(unique(y)) #amount of classes
I <- diag(num_classes) #Identity matrix
Y <- matrix(0, m, num_classes) #Binary matrix of the class
for(i in 1:m){
Y[i,] <- I[y[i],]
}
#Column_Names and constructing the dataset with binary label
labelColumnNames <- paste("label", 0:9, sep = "")
featuresColumnNames <- colnames(digits_dataset)[-1]
#Calculation for 60/20/20
b1 <- m * 0.6
b2 <- b1 + m * 0.2
#Separate dataset into 60/20/20
digits_train_set <- digits_dataset[1:b1, ]
digits_validation_set <- digits_dataset[(b1+1):b2, ]
digits_test_set <- digits_dataset[(b2+1):m, ]
#Binary dataset for Training the model
digits_train_binary <- cbind(Y[1:b1,], digits_train_set[,-1])
colnames(digits_train_binary) <- c(labelColumnNames, featuresColumnNames)
###Trainining model###
print("Training Neural Network...")
f <- as.formula(paste(paste(labelColumnNames, collapse = "+"),
"~",
paste(featuresColumnNames, collapse = "+")))
model <- neuralnet(f, data=digits_train_binary, hidden=hidden_layer_size,
threshold = 0.01,  lifesign="full",
lifesign.step = 10, linear.output = FALSE)
###Training fit and test accuracy
print("Model evaluation...")
#Classify the data
classTrain <- classify(model, digits_train_set[,-1])
classTest <- classify(model, digits_test_set[,-1])
#Calculate error
trainFit <- round(mean(digits_train_set[1] == classTrain), digits=2)
testAcc <- round(mean(digits_test_set[1] == classTest), digits=2)
print(paste("Training fit:", trainFit*100, "%"))
print(paste("Test accuracy:", testAcc*100, "%"))
classify(model, digits_train_set[,-1])
classify(model, digits_test_set[,-1])
classify(model, digits_train_set[,-1])
#main project script
#R Digits Recognition Neural Networks
#Daniel Freitas and Alex Shkunov
#
#Date: 23.10.2014
#Thesis: Haaga-Helia UAS
#Removes objects from main memory
rm(list=ls())
#Import stuff
library(neuralnet)
source('classify.r')
#Global variables
digits_FileName <- "../trainLoadTry_headers.csv"
hidden_layer_size <- 5
maxiter = 200 # Optimisation steps for Performance control
tr = 5 #Threshold for partial derevative for Performance control
#run actual stuff
print("Starting Actual Stuff")
###Data preprocessing###
#loading into the main memory
digits_dataset <- read.csv(digits_FileName)
print("Data Loaded...")
m <- nrow(digits_dataset)
#Label binary transformation
y <- digits_dataset[,1] + 1 # +1 for shift, so Zero is 1st class, One is 2nd class....
num_classes <- length(unique(y)) #amount of classes
I <- diag(num_classes) #Identity matrix
Y <- matrix(0, m, num_classes) #Binary matrix of the class
for(i in 1:m){
Y[i,] <- I[y[i],]
}
#Column_Names and constructing the dataset with binary label
labelColumnNames <- paste("label", 0:9, sep = "")
featuresColumnNames <- colnames(digits_dataset)[-1]
#Calculation for 60/20/20
b1 <- m * 0.6
b2 <- b1 + m * 0.2
#Separate dataset into 60/20/20
digits_train_set <- digits_dataset[1:b1, ]
digits_validation_set <- digits_dataset[(b1+1):b2, ]
digits_test_set <- digits_dataset[(b2+1):m, ]
#Binary dataset for Training the model
digits_train_binary <- cbind(Y[1:b1,], digits_train_set[,-1])
colnames(digits_train_binary) <- c(labelColumnNames, featuresColumnNames)
###Trainining model###
print("Training Neural Network...")
f <- as.formula(paste(paste(labelColumnNames, collapse = "+"),
"~",
paste(featuresColumnNames, collapse = "+")))
model <- neuralnet(f, data=digits_train_binary, hidden=hidden_layer_size,
threshold = 0.01, lifesign="full",
lifesign.step = 10, linear.output = FALSE)
###Training fit and test accuracy
print("Model evaluation...")
#Classify the data
classTrain <- classify(model, digits_train_set[,-1])
classTest <- classify(model, digits_test_set[,-1])
#Calculate error
trainFit <- round(mean(digits_train_set[1] == classTrain), digits=2)
testAcc <- round(mean(digits_test_set[1] == classTest), digits=2)
print(paste("Training fit:", trainFit*100, "%"))
print(paste("Test accuracy:", testAcc*100, "%"))
save.image("C:/DLF/Projects/thesis-project-x/program/r_digits_recognition/.RData")
ls()
a<-1
b<-0
c <- list=a,b
c <- list=(a,b)
list=(a,b)
rm(a,b)
#main project script
#R Digits Recognition Neural Networks
#Daniel Freitas and Alex Shkunov
#
#Date: 23.10.2014
#Thesis: Haaga-Helia UAS
#Removes objects from main memory
rm(list=ls())
#Import stuff
library(neuralnet)
source('classify.r')
#Global variables
digits_FileName <- "../train_headers_1to5000.csv"
hidden_layer_size <- 5
maxiter = 200 # Optimisation steps for Performance control
tr = 5 #Threshold for partial derevative for Performance control
#run actual stuff
print("Starting Actual Stuff")
###Data preprocessing###
#loading into the main memory
digits_dataset <- read.csv(digits_FileName)
print("Data Loaded...")
m <- nrow(digits_dataset)
#Label binary transformation
y <- digits_dataset[,1] + 1 # +1 for shift, so Zero is 1st class, One is 2nd class....
num_classes <- length(unique(y)) #amount of classes
I <- diag(num_classes) #Identity matrix
Y <- matrix(0, m, num_classes) #Binary matrix of the class
for(i in 1:m){
Y[i,] <- I[y[i],]
}
#Column_Names and constructing the dataset with binary label
labelColumnNames <- paste("label", 0:9, sep = "")
featuresColumnNames <- colnames(digits_dataset)[-1]
#Calculation for 60/20/20
b1 <- m * 0.6
b2 <- b1 + m * 0.2
#Separate dataset into 60/20/20
digits_train_set <- digits_dataset[1:b1, ]
digits_validation_set <- digits_dataset[(b1+1):b2, ]
digits_test_set <- digits_dataset[(b2+1):m, ]
#Binary dataset for Training the model
digits_train_binary <- cbind(Y[1:b1,], digits_train_set[,-1])
colnames(digits_train_binary) <- c(labelColumnNames, featuresColumnNames)
##Temporary, clean memory a bit
rm(digits_FileName, digits_dataset, m, y, num_classes, I, Y, b1, b2)
###Trainining model###
print("Training Neural Network...")
f <- as.formula(paste(paste(labelColumnNames, collapse = "+"),
"~",
paste(featuresColumnNames, collapse = "+")))
model <- neuralnet(f, data=digits_train_binary, hidden=hidden_layer_size,
threshold = tr, lifesign="full",
lifesign.step = 10, linear.output = FALSE)
###Training fit and test accuracy
print("Model evaluation...")
#Classify the data
classTrain <- classify(model, digits_train_set[,-1])
classTest <- classify(model, digits_test_set[,-1])
#Calculate error
trainFit <- round(mean(digits_train_set[1] == classTrain), digits=2)
testAcc <- round(mean(digits_test_set[1] == classTest), digits=2)
print(paste("Training fit:", trainFit*100, "%"))
print(paste("Test accuracy:", testAcc*100, "%"))
#main project script
#R Digits Recognition Neural Networks
#Daniel Freitas and Alex Shkunov
#
#Date: 23.10.2014
#Thesis: Haaga-Helia UAS
#Removes objects from main memory
rm(list=ls())
#Import stuff
library(neuralnet)
source('classify.r')
#Global variables
digits_FileName <- "../train_headers_1to5000.csv"
hidden_layer_size <- 50
maxiter = 200 # Optimisation steps for Performance control
tr = 5 #Threshold for partial derevative for Performance control
#run actual stuff
print("Starting Actual Stuff")
###Data preprocessing###
#loading into the main memory
digits_dataset <- read.csv(digits_FileName)
print("Data Loaded...")
m <- nrow(digits_dataset)
#Label binary transformation
y <- digits_dataset[,1] + 1 # +1 for shift, so Zero is 1st class, One is 2nd class....
num_classes <- length(unique(y)) #amount of classes
I <- diag(num_classes) #Identity matrix
Y <- matrix(0, m, num_classes) #Binary matrix of the class
for(i in 1:m){
Y[i,] <- I[y[i],]
}
#Column_Names and constructing the dataset with binary label
labelColumnNames <- paste("label", 0:9, sep = "")
featuresColumnNames <- colnames(digits_dataset)[-1]
#Calculation for 60/20/20
b1 <- m * 0.6
b2 <- b1 + m * 0.2
#Separate dataset into 60/20/20
digits_train_set <- digits_dataset[1:b1, ]
digits_validation_set <- digits_dataset[(b1+1):b2, ]
digits_test_set <- digits_dataset[(b2+1):m, ]
#Binary dataset for Training the model
digits_train_binary <- cbind(Y[1:b1,], digits_train_set[,-1])
colnames(digits_train_binary) <- c(labelColumnNames, featuresColumnNames)
##Temporary, clean memory a bit
rm(digits_FileName, digits_dataset, m, y, num_classes, I, Y, b1, b2)
###Trainining model###
print("Training Neural Network...")
f <- as.formula(paste(paste(labelColumnNames, collapse = "+"),
"~",
paste(featuresColumnNames, collapse = "+")))
model <- neuralnet(f, data=digits_train_binary, hidden=hidden_layer_size,
threshold = tr, lifesign="full",
lifesign.step = 10, linear.output = FALSE)
###Training fit and test accuracy
print("Model evaluation...")
#Classify the data
classTrain <- classify(model, digits_train_set[,-1])
classTest <- classify(model, digits_test_set[,-1])
#Calculate error
trainFit <- round(mean(digits_train_set[1] == classTrain), digits=2)
testAcc <- round(mean(digits_test_set[1] == classTest), digits=2)
print(paste("Training fit:", trainFit*100, "%"))
print(paste("Test accuracy:", testAcc*100, "%"))
?neuralnet
source('main.r')
source('main.r')
source('main.r')
source('main.r')
source('main.r')
source('main.r')
source('main.r')
source('main.r')
source('main.r')
source('main.r')
source('main.r')
source('main.r')
source('main.r')
#Removes objects from main memory
rm(list=ls())
#Import stuff
library(neuralnet)
source('classify.R')
#Global variables
digits_FileName <- "../train_headers_1to5000.csv"
hidden_layer_size <- 20
tr = 1 #Threshold for partial derevative for Performance control
#run actual stuff
print("Starting Actual Stuff")
###Data preprocessing###
#loading into the main memory
digits_dataset <- read.csv(digits_FileName)
m <- nrow(digits_dataset)
print(paste("Data Loaded... ", m, " rows"))
library(stats)
princomp(digits_dataset[,-1])
pc.cr <- princomp(digits_dataset[,-1])
loadings(pc.cr)
pc.cr$scores
pca.plot <- xyplot(pc.cr$scores[,2] ~ pc.cr$scores[,1])
library(lattice)
pca.plot <- xyplot(pc.cr$scores[,2] ~ pc.cr$scores[,1])
pca.plot$xlab <- "First Component"
pca.plot$ylab <- "Second Component"
pca.plot
pc.cr$scores[1,1]
pc.cr$scores[1,2]
pc.cr$scores[1,3]
pc.cr$scores[1,4]
pc.cr$scores[1,5]
pc.cr$scores[1,1]
pc.cr$scores[1:5,1]
p <- x$scores[,1:2]
library(stats)
library(lattice)
summary(x <- princomp(digits_dataset[,-1]))
loadings(x)
p <- x$scores[,1:2]
pca.plot <- xyplot(x$scores[,2] ~ x$scores[,1])
pca.plot$xlab <- "First Component"
pca.plot$ylab <- "Second Component"
pca.plot
colnames(p)
colnames(p)
N = 5
p <- x$scores[,1:N]
colnames(p)
p[1]
p[,1]
digits_FileName <- "../train_full.csv"
digits_FileName <- "../train_full.csv"
#loading into the main memory
digits_dataset <- read.csv(digits_FileName)
library(stats)
library(lattice)
summary(x <- princomp(digits_dataset[,-1]))
loadings(x)
pca.plot <- xyplot(x$scores[,2] ~ x$scores[,1])
pca.plot$xlab <- "First Component"
pca.plot$ylab <- "Second Component"
pca.plot
p <- x$scores[,1:5]
View(p)
NewData <- cbind(digits_dataset[,1], p)
write.csv(NewData, paste("reduced_", N, "_rows_", nrow(p), ".csv"), row.names=FALSE)
write.csv(NewData, paste("reduced_", 5, "_rows_", nrow(p), ".csv"), row.names=FALSE)
#main project script
#R Digits Recognition Neural Networks
#Daniel Freitas and Alex Shkunov
#
#Date: 23.10.2014
#Thesis: Haaga-Helia UAS
#Removes objects from main memory
rm(list=ls())
#Import stuff
library(neuralnet)
source('classify.R')
#Global variables
digits_FileName <- "../reduced_5_rows_42000.csv"
hidden_layer_size <- 20
tr = 1 #Threshold for partial derevative for Performance control
#run actual stuff
print("Starting Actual Stuff")
###Data preprocessing###
#loading into the main memory
digits_dataset <- read.csv(digits_FileName)
m <- nrow(digits_dataset)
print(paste("Data Loaded... ", m, " rows"))
#Label binary transformation
y <- digits_dataset[,1] + 1 # +1 for shift, so Zero is 1st class, One is 2nd class....
num_classes <- length(unique(y)) #amount of classes
I <- diag(num_classes) #Identity matrix
Y <- matrix(0, m, num_classes) #Binary matrix of the class
for(i in 1:m){
Y[i,] <- I[y[i],]
}
#Column_Names and constructing the dataset with binary label
labelColumnNames <- paste("label", 0:9, sep = "")
featuresColumnNames <- colnames(digits_dataset)[-1]
#Calculation for 60/20/20
b1 <- m * 0.6
b2 <- b1 + m * 0.2
#Separate dataset into 60/20/20
digits_train_set <- digits_dataset[1:b1, ]
digits_validation_set <- digits_dataset[(b1+1):b2, ]
digits_test_set <- digits_dataset[(b2+1):m, ]
print(paste("Train_set ", nrow(digits_train_set), " rows"))
print(paste("Test_set ", nrow(digits_test_set), " rows"))
#Binary dataset for Training the model
digits_train_binary <- cbind(Y[1:b1,], digits_train_set[,-1])
colnames(digits_train_binary) <- c(labelColumnNames, featuresColumnNames)
##Temporary, clean memory a bit
rm(digits_FileName, digits_dataset, m, y, num_classes, I, Y, i, b1, b2)
###Trainining model###
print(paste("Training Neural Network... ", hidden_layer_size, " Hidden units"))
f <- as.formula(paste(paste(labelColumnNames, collapse = "+"),
"~",
paste(featuresColumnNames, collapse = "+")))
model <- neuralnet(f, data=digits_train_binary, hidden=hidden_layer_size,
threshold = tr, lifesign="full",
lifesign.step = 10, linear.output = FALSE)
###Training fit and test accuracy
print("Model evaluation... ")
#Classify the data
classTrain <- classify(model, digits_train_set[,-1])
classTest <- classify(model, digits_test_set[,-1])
#Calculate error
trainFit <- round(mean(digits_train_set[,1] == classTrain), digits=2)
testAcc <- round(mean(digits_test_set[,1] == classTest), digits=2)
print(paste("Training fit:", trainFit*100, "%"))
print(paste("Test accuracy:", testAcc*100, "%"))
#main project script
#R Digits Recognition Neural Networks
#Daniel Freitas and Alex Shkunov
#
#Date: 23.10.2014
#Thesis: Haaga-Helia UAS
#Removes objects from main memory
rm(list=ls())
#Import stuff
library(neuralnet)
source('classify.R')
#Global variables
digits_FileName <- "../reduced_5_rows_42000.csv"
hidden_layer_size <- 50
tr = 2 #Threshold for partial derevative for Performance control
#run actual stuff
print("Starting Actual Stuff")
###Data preprocessing###
#loading into the main memory
digits_dataset <- read.csv(digits_FileName)
m <- nrow(digits_dataset)
print(paste("Data Loaded... ", m, " rows"))
#Label binary transformation
y <- digits_dataset[,1] + 1 # +1 for shift, so Zero is 1st class, One is 2nd class....
num_classes <- length(unique(y)) #amount of classes
I <- diag(num_classes) #Identity matrix
Y <- matrix(0, m, num_classes) #Binary matrix of the class
for(i in 1:m){
Y[i,] <- I[y[i],]
}
#Column_Names and constructing the dataset with binary label
labelColumnNames <- paste("label", 0:9, sep = "")
featuresColumnNames <- colnames(digits_dataset)[-1]
#Calculation for 60/20/20
b1 <- m * 0.6
b2 <- b1 + m * 0.2
#Separate dataset into 60/20/20
digits_train_set <- digits_dataset[1:b1, ]
digits_validation_set <- digits_dataset[(b1+1):b2, ]
digits_test_set <- digits_dataset[(b2+1):m, ]
print(paste("Train_set ", nrow(digits_train_set), " rows"))
print(paste("Test_set ", nrow(digits_test_set), " rows"))
#Binary dataset for Training the model
digits_train_binary <- cbind(Y[1:b1,], digits_train_set[,-1])
colnames(digits_train_binary) <- c(labelColumnNames, featuresColumnNames)
##Temporary, clean memory a bit
rm(digits_FileName, digits_dataset, m, y, num_classes, I, Y, i, b1, b2)
###Trainining model###
print(paste("Training Neural Network... ", hidden_layer_size, " Hidden units"))
f <- as.formula(paste(paste(labelColumnNames, collapse = "+"),
"~",
paste(featuresColumnNames, collapse = "+")))
model <- neuralnet(f, data=digits_train_binary, hidden=hidden_layer_size,
threshold = tr, lifesign="full",
lifesign.step = 10, linear.output = FALSE)
###Training fit and test accuracy
print("Model evaluation... ")
#Classify the data
classTrain <- classify(model, digits_train_set[,-1])
classTest <- classify(model, digits_test_set[,-1])
#Calculate error
trainFit <- round(mean(digits_train_set[,1] == classTrain), digits=2)
testAcc <- round(mean(digits_test_set[,1] == classTest), digits=2)
print(paste("Training fit:", trainFit*100, "%"))
print(paste("Test accuracy:", testAcc*100, "%"))
